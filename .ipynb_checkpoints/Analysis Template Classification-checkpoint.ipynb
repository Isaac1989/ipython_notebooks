{
 "metadata": {
  "name": "",
  "signature": "sha256:2419c194959b7947b5101b9110f980570be605b46bdcc90c39dda38cfdcf4bf9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Project Overview#\n",
      "##1. Define Problem##\n",
      "##2. Prepare Data##\n",
      "##3. Exploratory Data Analysis & Further Feature Selection##\n",
      "##4. Learning, Algorithm Comparison, & Model Selection##\n",
      "##5. Model Visualization##\n",
      "##6. Interpretation & Conclusions##\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#1. Defining the Problem#\n",
      "##Motivation##\n",
      "- Uses\n",
      "- Benefits\n",
      "\n",
      "##Available Data##\n",
      "- What are the provided features / attributes?\n",
      "- Constraints imposed by data\n",
      "\n",
      "##Problem Desciption##\n",
      "- Informal\n",
      "- Formal\n",
      "- Assumptions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#2. Preparing the Data#\n",
      "- a. Importing\n",
      "- b. Feature Selection\n",
      "  - For the current problem, what are the relevant features? Which features are *NOT* needed\n",
      "- c. Feature Coding\n",
      "  - Going beyond the "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2a. Importing the data##\n",
      "Here I use [Python Pandas](http://pandas.pydata.org/) to read in the provided .csv data files and to perform relevant joins."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SOME INITIAL SETUP\n",
      "import os\n",
      "import pandas as pd\n",
      "import csv\n",
      "pd.set_option('display.width',120) \n",
      "pd.set_option('display.max_rows', 10)\n",
      "\n",
      "# LOAD THE TRAINING DATA\n",
      "data_file_name = '/home/dustin/kaggle/titanic/train.csv'\n",
      "data_frame = pd.read_csv(data_file_name)\n",
      "\n",
      "print data_frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     PassengerId  Survived  Pclass                                               Name     Sex  Age  SibSp  Parch  \\\n",
        "0              1         0       3                            Braund, Mr. Owen Harris    male   22      1      0   \n",
        "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1      0   \n",
        "2              3         1       3                             Heikkinen, Miss. Laina  female   26      0      0   \n",
        "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1      0   \n",
        "4              5         0       3                           Allen, Mr. William Henry    male   35      0      0   \n",
        "..           ...       ...     ...                                                ...     ...  ...    ...    ...   \n",
        "886          887         0       2                              Montvila, Rev. Juozas    male   27      0      0   \n",
        "887          888         1       1                       Graham, Miss. Margaret Edith  female   19      0      0   \n",
        "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female  NaN      1      2   \n",
        "889          890         1       1                              Behr, Mr. Karl Howell    male   26      0      0   \n",
        "890          891         0       3                                Dooley, Mr. Patrick    male   32      0      0   \n",
        "\n",
        "               Ticket     Fare Cabin Embarked  \n",
        "0           A/5 21171   7.2500   NaN        S  \n",
        "1            PC 17599  71.2833   C85        C  \n",
        "2    STON/O2. 3101282   7.9250   NaN        S  \n",
        "3              113803  53.1000  C123        S  \n",
        "4              373450   8.0500   NaN        S  \n",
        "..                ...      ...   ...      ...  \n",
        "886            211536  13.0000   NaN        S  \n",
        "887            112053  30.0000   B42        S  \n",
        "888        W./C. 6607  23.4500   NaN        S  \n",
        "889            111369  30.0000  C148        C  \n",
        "890            370376   7.7500   NaN        Q  \n",
        "\n",
        "[891 rows x 12 columns]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2b. Feature Selection###\n",
      "Here I remove variables that do not appear to be helpful, either because they are redundant with other features, there are too many missing values, etc. This also helps visualize the data frame for further analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preproc_step_1(data_frame):\n",
      "    # INITIAL REMOVAL FOR CONCISE VISUALIZATION\n",
      "    rm_cols = ['Name','Cabin','Ticket','PassengerId']\n",
      "    data_frame = data_frame.drop(rm_cols, axis=1) \n",
      "    \n",
      "    # SANITY CHECK\n",
      "    print data_frame\n",
      "    return data_frame\n",
      "\n",
      "data_frame = preproc_step_1(data_frame)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked\n",
        "0           0       3    male   22      1      0   7.2500        S\n",
        "1           1       1  female   38      1      0  71.2833        C\n",
        "2           1       3  female   26      0      0   7.9250        S\n",
        "3           1       1  female   35      1      0  53.1000        S\n",
        "4           0       3    male   35      0      0   8.0500        S\n",
        "..        ...     ...     ...  ...    ...    ...      ...      ...\n",
        "886         0       2    male   27      0      0  13.0000        S\n",
        "887         1       1  female   19      0      0  30.0000        S\n",
        "888         0       3  female  NaN      1      2  23.4500        S\n",
        "889         1       1    male   26      0      0  30.0000        C\n",
        "890         0       3    male   32      0      0   7.7500        Q\n",
        "\n",
        "[891 rows x 8 columns]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2c. Feature Coding##\n",
      "Here I use Pandas to code the categorical into numeric domains\n",
      "\n",
      "We first replace missing entries by a descriptive statistic \n",
      "\n",
      "- MODE: categorical variables: 'Embarked','Pclass','Survived', 'Sex'\n",
      "- MEDIAN: continuous or nominal ariables: 'Age', 'Fare', 'SibSp'\n",
      "\n",
      "We then dummy code the categorical variables (i.e. independent, non-nominal variables)\n",
      "\n",
      "- 1-of-K ENCODING: 'Sex','Embarked'\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# THE STEPS IN 2C ARE PERFORMED HERE\n",
      "def preproc_step_2(data_frame,mode='train'):\n",
      "    # REPLACE NULL VALUES WITH MODE\n",
      "    if mode is 'train':\n",
      "        replace_empty_with_mode = ['Embarked','Pclass','Survived','Sex']\n",
      "    else:\n",
      "        replace_empty_with_mode = ['Embarked','Pclass','Sex'] # SURVIVED ISN'T IN TESTING SET\n",
      "    \n",
      "    for col in replace_empty_with_mode:\n",
      "        if len(data_frame[col][data_frame[col].isnull()]) > 0:\n",
      "                data_frame[col][ data_frame[col].isnull() ] = data_frame[col].mode().values\n",
      "                \n",
      "    # REPLACE NULL VALUES WITH MEDIAN\n",
      "    replace_empty_with_median = ['Age', 'Fare','SibSp']\n",
      "    for col in replace_empty_with_median:    \n",
      "        if len(data_frame[col][data_frame[col].isnull()]) > 0:\n",
      "            data_frame[col][ data_frame[col].isnull() ] = data_frame[col].median()\n",
      "\n",
      "    # MAP CATEGORICAL VARIABLES\n",
      "    code_as_dummy = ['Sex','Embarked']    \n",
      "    for col in code_as_dummy:\n",
      "        dummies = pd.get_dummies(data_frame[col])\n",
      "        data_frame = data_frame.join(dummies,how='left')\n",
      "\n",
      "    # REMOVE ORIGINAL CATEGORICAL VARIABLES\n",
      "    data_frame = data_frame.drop(code_as_dummy,axis=1)    \n",
      "    if mode is 'train':\n",
      "        data = data_frame.values\n",
      "        features = data[:,1:]\n",
      "        targets = data[:,0]\n",
      "    else:\n",
      "        features = data_frame.values\n",
      "        targets = None\n",
      "        \n",
      "    # IF RENAMING ANY COLUMNS\n",
      "    rename_dict = {\"C\": \"Cherbourg\", \"Q\": \"Queenstown\", \"S\": \"Southampton\", \"male\": \"Male\", \"female\": \"Female\"}\n",
      "    data_frame = data_frame.rename(columns=rename_dict)\n",
      "        \n",
      "    print '\\n%sing features: \\n' % mode \n",
      "    print data_frame\n",
      "    return features, targets, data_frame\n",
      "\n",
      "data_train, targets_train, data_frame_train = preproc_step_2(data_frame)\n",
      "# SANITY CHECK\n",
      "#print train_data, train_data.shape\n",
      "#print train_targets, len(train_targets)\n",
      "\n",
      "# PERFORM PREPROCESSING ON THE TESTING DATA\n",
      "data_file_name = '/home/dustin/kaggle/titanic/test.csv'\n",
      "data_frame = pd.read_csv(data_file_name)\n",
      "out_idx = data_frame[\"PassengerId\"].values\n",
      "data_frame = preproc_step_1(data_frame)\n",
      "data_test, targets_test, data_frame_test = preproc_step_2(data_frame,mode='test')\n",
      "\n",
      "feature_labels = data_frame_test.columns\n",
      "# SANITY CHECKS\n",
      "#print test_data, test_data.shape\n",
      "#print test_labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "training features: \n",
        "\n",
        "     Survived  Pclass  Age  SibSp  Parch     Fare  Female  Male  Cherbourg  Queenstown  Southampton\n",
        "0           0       3   22      1      0   7.2500       0     1          0           0            1\n",
        "1           1       1   38      1      0  71.2833       1     0          1           0            0\n",
        "2           1       3   26      0      0   7.9250       1     0          0           0            1\n",
        "3           1       1   35      1      0  53.1000       1     0          0           0            1\n",
        "4           0       3   35      0      0   8.0500       0     1          0           0            1\n",
        "..        ...     ...  ...    ...    ...      ...     ...   ...        ...         ...          ...\n",
        "886         0       2   27      0      0  13.0000       0     1          0           0            1\n",
        "887         1       1   19      0      0  30.0000       1     0          0           0            1\n",
        "888         0       3   28      1      2  23.4500       1     0          0           0            1\n",
        "889         1       1   26      0      0  30.0000       0     1          1           0            0\n",
        "890         0       3   32      0      0   7.7500       0     1          0           1            0\n",
        "\n",
        "[891 rows x 11 columns]\n",
        "     Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
        "0         3    male  34.5      0      0    7.8292        Q\n",
        "1         3  female  47.0      1      0    7.0000        S\n",
        "2         2    male  62.0      0      0    9.6875        Q\n",
        "3         3    male  27.0      0      0    8.6625        S\n",
        "4         3  female  22.0      1      1   12.2875        S\n",
        "..      ...     ...   ...    ...    ...       ...      ...\n",
        "413       3    male   NaN      0      0    8.0500        S\n",
        "414       1  female  39.0      0      0  108.9000        C\n",
        "415       3    male  38.5      0      0    7.2500        S\n",
        "416       3    male   NaN      0      0    8.0500        S\n",
        "417       3    male   NaN      1      1   22.3583        C\n",
        "\n",
        "[418 rows x 7 columns]\n",
        "\n",
        "testing features: \n",
        "\n",
        "     Pclass   Age  SibSp  Parch      Fare  Female  Male  Cherbourg  Queenstown  Southampton\n",
        "0         3  34.5      0      0    7.8292       0     1          0           1            0\n",
        "1         3  47.0      1      0    7.0000       1     0          0           0            1\n",
        "2         2  62.0      0      0    9.6875       0     1          0           1            0\n",
        "3         3  27.0      0      0    8.6625       0     1          0           0            1\n",
        "4         3  22.0      1      1   12.2875       1     0          0           0            1\n",
        "..      ...   ...    ...    ...       ...     ...   ...        ...         ...          ...\n",
        "413       3  27.0      0      0    8.0500       0     1          0           0            1\n",
        "414       1  39.0      0      0  108.9000       1     0          1           0            0\n",
        "415       3  38.5      0      0    7.2500       0     1          0           0            1\n",
        "416       3  27.0      0      0    8.0500       0     1          0           0            1\n",
        "417       3  27.0      1      1   22.3583       0     1          1           0            0\n",
        "\n",
        "[418 rows x 10 columns]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#3. Exploratory Data Analysis#"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3b. Descriptive Statistics##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '\\nTraining Data Statistics'\n",
      "data_frame_train.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training Data Statistics\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Female</th>\n",
        "      <th>Male</th>\n",
        "      <th>Cherbourg</th>\n",
        "      <th>Queenstown</th>\n",
        "      <th>Southampton</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>   0.383838</td>\n",
        "      <td>   2.308642</td>\n",
        "      <td>  29.361582</td>\n",
        "      <td>   0.523008</td>\n",
        "      <td>   0.381594</td>\n",
        "      <td>  32.204208</td>\n",
        "      <td>   0.352413</td>\n",
        "      <td>   0.647587</td>\n",
        "      <td>   0.188552</td>\n",
        "      <td>   0.086420</td>\n",
        "      <td>   0.725028</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>   0.486592</td>\n",
        "      <td>   0.836071</td>\n",
        "      <td>  13.019697</td>\n",
        "      <td>   1.102743</td>\n",
        "      <td>   0.806057</td>\n",
        "      <td>  49.693429</td>\n",
        "      <td>   0.477990</td>\n",
        "      <td>   0.477990</td>\n",
        "      <td>   0.391372</td>\n",
        "      <td>   0.281141</td>\n",
        "      <td>   0.446751</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.420000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>  22.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   7.910400</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  28.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  14.454200</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  35.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  31.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  80.000000</td>\n",
        "      <td>   8.000000</td>\n",
        "      <td>   6.000000</td>\n",
        "      <td> 512.329200</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "         Survived      Pclass         Age       SibSp       Parch        Fare      Female        Male   Cherbourg  \\\n",
        "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
        "mean     0.383838    2.308642   29.361582    0.523008    0.381594   32.204208    0.352413    0.647587    0.188552   \n",
        "std      0.486592    0.836071   13.019697    1.102743    0.806057   49.693429    0.477990    0.477990    0.391372   \n",
        "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
        "25%      0.000000    2.000000   22.000000    0.000000    0.000000    7.910400    0.000000    0.000000    0.000000   \n",
        "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200    0.000000    1.000000    0.000000   \n",
        "75%      1.000000    3.000000   35.000000    1.000000    0.000000   31.000000    1.000000    1.000000    0.000000   \n",
        "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200    1.000000    1.000000    1.000000   \n",
        "\n",
        "       Queenstown  Southampton  \n",
        "count  891.000000   891.000000  \n",
        "mean     0.086420     0.725028  \n",
        "std      0.281141     0.446751  \n",
        "min      0.000000     0.000000  \n",
        "25%      0.000000     0.000000  \n",
        "50%      0.000000     1.000000  \n",
        "75%      0.000000     1.000000  \n",
        "max      1.000000     1.000000  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '\\nTesting Data Statistics'\n",
      "data_frame_test.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Testing Data Statistics\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Female</th>\n",
        "      <th>Male</th>\n",
        "      <th>Cherbourg</th>\n",
        "      <th>Queenstown</th>\n",
        "      <th>Southampton</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "      <td> 418.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>   2.265550</td>\n",
        "      <td>  29.599282</td>\n",
        "      <td>   0.447368</td>\n",
        "      <td>   0.392344</td>\n",
        "      <td>  35.576535</td>\n",
        "      <td>   0.363636</td>\n",
        "      <td>   0.636364</td>\n",
        "      <td>   0.244019</td>\n",
        "      <td>   0.110048</td>\n",
        "      <td>   0.645933</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>   0.841838</td>\n",
        "      <td>  12.703770</td>\n",
        "      <td>   0.896760</td>\n",
        "      <td>   0.981429</td>\n",
        "      <td>  55.850103</td>\n",
        "      <td>   0.481622</td>\n",
        "      <td>   0.481622</td>\n",
        "      <td>   0.430019</td>\n",
        "      <td>   0.313324</td>\n",
        "      <td>   0.478803</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.170000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>  23.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   7.895800</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  27.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  14.454200</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  35.750000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  31.471875</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  76.000000</td>\n",
        "      <td>   8.000000</td>\n",
        "      <td>   9.000000</td>\n",
        "      <td> 512.329200</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "           Pclass         Age       SibSp       Parch        Fare      Female        Male   Cherbourg  Queenstown  \\\n",
        "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n",
        "mean     2.265550   29.599282    0.447368    0.392344   35.576535    0.363636    0.636364    0.244019    0.110048   \n",
        "std      0.841838   12.703770    0.896760    0.981429   55.850103    0.481622    0.481622    0.430019    0.313324   \n",
        "min      1.000000    0.170000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
        "25%      1.000000   23.000000    0.000000    0.000000    7.895800    0.000000    0.000000    0.000000    0.000000   \n",
        "50%      3.000000   27.000000    0.000000    0.000000   14.454200    0.000000    1.000000    0.000000    0.000000   \n",
        "75%      3.000000   35.750000    1.000000    0.000000   31.471875    1.000000    1.000000    0.000000    0.000000   \n",
        "max      3.000000   76.000000    8.000000    9.000000  512.329200    1.000000    1.000000    1.000000    1.000000   \n",
        "\n",
        "       Southampton  \n",
        "count   418.000000  \n",
        "mean      0.645933  \n",
        "std       0.478803  \n",
        "min       0.000000  \n",
        "25%       0.000000  \n",
        "50%       1.000000  \n",
        "75%       1.000000  \n",
        "max       1.000000  "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Take-homes**\n",
      "- "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3c. Data Visualization##\n",
      "- Marginal histograms\n",
      "- Pairwise scatterplots"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "close(\"all\")\n",
      "\n",
      "# PARALLEL COORDINATES PLOT\n",
      "plt.figure(1)\n",
      "data_frame_norm = data_frame_train/ data_frame_train.max()  # RESCALE FROM 0,1\n",
      "# (PERHAPS JITTER THE CATEGORICAL VARIABLES TO AID IN VISUALIZATION)\n",
      "ax = pd.tools.plotting.parallel_coordinates(data_frame_norm,'Survived', color=['red','blue'])\n",
      "ax.set_axis_bgcolor('white') \n",
      "plt.xticks(rotation=45)\n",
      "\n",
      "\n",
      "\n",
      "# SCATTER MATRIX PLOT (KERNEL DENSITY ALONG CENTER)\n",
      "plt.figure(figsize=(10,10))\n",
      "df_scatter_mat = data_frame_train[[\"Male\",\"Female\",\"Age\",\"Pclass\",\"Fare\",\"Survived\"]]\n",
      "_ = pd.scatter_matrix(df_scatter_mat,diagonal='hist',color='red')\n",
      "\n",
      "\n",
      "# CROSS-TABULATION PLOT\n",
      "plt.figure(figsize=(10,10))\n",
      "cross_tab_male = pd.crosstab([data_frame_train[\"Pclass\"], \n",
      "                              data_frame_train[\"Male\"]], data_frame_train[\"Survived\"].astype(bool))\n",
      "cross_tab_male.plot(kind='bar', stacked=True, color=['red','blue'], grid=False)\n",
      "plt.title(\"Cross-tabulation Plot\")\n",
      "\n",
      "# STANDARD HISTOGRAM\n",
      "plt.figure()\n",
      "data_frame_train.Fare.hist(); plt.title('Histogram of Fares')\n",
      "\n",
      "# GROUPED BOXPLOT WITH DATA\n",
      "def my_boxplot(x_group,y_group,offset=0,plot_data=0):\n",
      "    bp = data_frame_train.boxplot(column=y_group, by=x_group, grid=False)\n",
      "    bp.set_axis_bgcolor('w')\n",
      "    if plot_data:\n",
      "        for i in unique(data_frame_train[x_group].values+offset):\n",
      "            y = data_frame_train[y_group][data_frame_train[x_group]==i-offset].dropna()\n",
      "            # JITTER FOR VISUALIZATION\n",
      "            x = np.random.normal(i, 0.02, size=len(y))\n",
      "            plot(x, y, 'k.', alpha=0.2)\n",
      "        \n",
      "my_boxplot([\"Survived\",\"Pclass\"],\"Age\",1)\n",
      "my_boxplot(\"Survived\",\"Fare\",1)\n",
      "\n",
      "\n",
      "# STANDARD SCATTERPLOT\n",
      "def my_scatter(x_var,y_var,size=50, alpha=0.8, color='k', cmap='hot'):\n",
      "    plt.scatter(data_frame_train[x_var], data_frame_train[y_var], \n",
      "                s=size, c=color, alpha=alpha, cmap=cmap)\n",
      "    xlabel(x_var); ylabel(y_var)\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "my_scatter('Age','Fare',\n",
      "           size=(.5+data_frame_train[\"Survived\"].values)*100,\n",
      "           color=(.5+data_frame_train[\"Survived\"].values)*100)\n",
      "\n",
      "# TRELLIS PLOTS IN 1D USING RPLOT\n",
      "from pandas.tools.rplot import *\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "df = data_frame_train[data_frame_train['Age'].notnull() & data_frame['Fare'].notnull()]\n",
      "tp = RPlot(df, x='Age')\n",
      "tp.add(TrellisGrid(['Pclass', 'Female']))\n",
      "#tp.add(GeomHistogram())\n",
      "tp.add(GeomDensity(colour='b'))\n",
      "_ = tp.render(gcf())\n",
      "\n",
      "\n",
      "# TRELLIS PLOTS IN 2D USING RPLOT\n",
      "from pandas.tools.rplot import *\n",
      "\n",
      "plt.figure(figsize=(10,10))\n",
      "df = data_frame_train[data_frame_train['Age'].notnull() & data_frame['Fare'].notnull()]\n",
      "tp = RPlot(df, x='Age',y='Fare')\n",
      "tp.add(TrellisGrid(['Pclass', 'Female']))\n",
      "tp.add(GeomScatter())\n",
      "#tp.add(GeomDensity2D())\n",
      "tp.add(GeomPolyFit(degree=3,colour='b'))\n",
      "_ = tp.render(gcf())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3d. Assessing Important Features##\n",
      "- Decompositions (PCA, ICA, NMF)\n",
      "- Feature Aggregation\n",
      "- Univariate Feature Selection \n",
      "  - $-\\log(p\\text{-value})$ from F-test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# UNIVARIATE FEATURE SELECTION (ADJUST IMPORT FOR RELEVANT TASK)\n",
      "from sklearn.feature_selection import SelectPercentile, f_classif, f_regression\n",
      "\n",
      "# DO FEATURE SELECTION\n",
      "selector = SelectPercentile(f_classif, percentile=10)\n",
      "selector.fit(data_train, targets_train)\n",
      "scores = -np.log10(selector.pvalues_)\n",
      "scores /= scores.max()\n",
      "\n",
      "# FEATURES TO KEEP\n",
      "keep_idx = scores > .05    \n",
      "\n",
      "# DISPLAY\n",
      "plt.figure(figsize=(10,10))\n",
      "plt.bar(arange(len(scores)), scores, width=.75, label=r'Univariate Feature Selection Score ($-\\log(p_{value})$)')\n",
      "plt.xticks(arange(len(scores)),feature_labels, rotation=45)\n",
      "plt.yticks(())\n",
      "plt.axis('tight')\n",
      "plt.legend(loc='best')\n",
      "plt.show()\n",
      "\n",
      "# NEED TO TEST FOR CORRELATIONS BETWEEN FEATURES TO BE SURE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Covariance##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.covariance import GraphLassoCV\n",
      "\n",
      "cov_model = GraphLassoCV(alphas=10)\n",
      "\n",
      "# STANDARDIZE AND FIT \n",
      "cov_model.fit(data_train/data_train.std(axis=0))\n",
      "plt.figure(figsize(10,10))\n",
      "plt.imshow(cov_model.covariance_,cmap='RdBu_r',interpolation='nearest')\n",
      "plt.colorbar()\n",
      "plt.xticks(arange(len(feature_labels))-.5,feature_labels,rotation=45)\n",
      "plt.yticks(arange(len(feature_labels)),feature_labels)\n",
      "plt.title('Sparse Covariance Estimate (LASSO)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<matplotlib.text.Text at 0x7f6bb564f490>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#4. Learning, Algorithm Comparison, & Model Selection#\n",
      "###Learning Algorithims Tested:###\n",
      "  - Logistic / Multinomial Regression \n",
      "    - Pros: \n",
      "    - Cons: \n",
      "  - Support Vector Machine Classifier\n",
      "    - Pros: nice methods for ranking important features ()\n",
      "    - Cons:\n",
      "  - Random Forests Classifier\n",
      "    - Pros: nice methods for ranking important features ()\n",
      "    - Cons:\n",
      "  - Gradient Boosting Classifier \n",
      "    - Pros: nice methods for ranking important features ()\n",
      "    - Cons:\n",
      "    \n",
      "###Cross-validation & Hyperparameter Selection###\n",
      "  - 5-fold CV\n",
      "    - Pros: Improves generalization\n",
      "    - Cons: Greater computational burden; 5 subsets *could* be insufficient for adequate estimate of distribution\n",
      "  - Randomized Hyperparameter Search (n=10)\n",
      "    - Pros: Exponentially more efficient than grid search ([Bergstra et al. 2012](http://jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)); involves less domain knowledge than does grid search (only requires a range)\n",
      "    - Cons: Can provide sub-optimal hyperparameters when compared to a fine-grained search grid"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Setup and Fitting Logistic Regression Classifier##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "from operator import itemgetter\n",
      "from scipy import stats as st\n",
      "`\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "def report(grid_scores, n_top=3):\n",
      "    \"\"\"For reporting best models\"\"\"\n",
      "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
      "    for i, score in enumerate(top_scores):\n",
      "        print(\"Model with rank: {0}\".format(i + 1))\n",
      "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
      "              score.mean_validation_score,\n",
      "              np.std(score.cv_validation_scores)))\n",
      "        print(\"Parameters: {0}\".format(score.parameters))\n",
      "        print(\"\")\n",
      "\n",
      "        \n",
      "# dict FOR BEST MODELS\n",
      "best_models = {}\n",
      "\n",
      "### INIT LOGISTIC REGRESSION CLASSIFER\n",
      "print '_'*20 + ' Logistic Regression Classifier ' + '_'*20 + '\\n'      \n",
      "clf_lr = LogisticRegression(dual=False)\n",
      "\n",
      "# PARAMETER DISTRIBUTION FOR LOGISTIC REGRESSION\n",
      "param_dist_lr = {\"C\": [0.01, 2.0],\n",
      "                 \"penalty\": [\"l1\",\"l2\"]}\n",
      "\n",
      "# RUN PARAMETER ESTIMATION\n",
      "n_iter_search = 20\n",
      "random_search_lr = RandomizedSearchCV(clf_lr, param_distributions=param_dist_lr,\n",
      "                                      n_iter=n_iter_search)\n",
      "# FIT\n",
      "start = time()\n",
      "random_search_lr.fit(data_train, targets_train)\n",
      "\n",
      "print(\"Logistic Regression Estimation using RandomizedSearchCV took %.2f seconds for %d candidates models\"\n",
      "      \"\\nBest Parameter settings:\" % ((time() - start), n_iter_search))\n",
      "print '_'*25 + '\\n'\n",
      "\n",
      "report(random_search_lr.grid_scores_)\n",
      "best_models['logistic'] = random_search_lr.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________ Logistic Regression Classifier ____________________\n",
        "\n",
        "Logistic Regression Estimation using RandomizedSearchCV took 0.30 seconds for 20 candidates models\n",
        "Best Parameter settings:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "_________________________\n",
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.790 (std: 0.003)\n",
        "Parameters: {'penalty': 'l1', 'C': 2.0}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.790 (std: 0.003)\n",
        "Parameters: {'penalty': 'l1', 'C': 2.0}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.790 (std: 0.003)\n",
        "Parameters: {'penalty': 'l1', 'C': 2.0}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Fitting SVM Classifier##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INIT SVM REGRESSION CLASSIFER\n",
      "print '_'*20 + ' Support Vector Machine Classifier ' + '_'*20 + '\\n'      \n",
      "clf_svm = SVC(cache_size=500, max_iter=2000)\n",
      "\n",
      "# PARAMETER DISTRIBUTION FOR SVM\n",
      "param_grid_svm = {\"C\": logspace(-2, 0,5),\n",
      "                  \"kernel\": [\"linear\"]} # WASTE OF COMPS. FOR \"RBF\"\n",
      "\n",
      "# RUN PARAMETER ESTIMATION\n",
      "grid_search_svm = GridSearchCV(clf_svm, param_grid=param_grid_svm)\n",
      "\n",
      "\n",
      "## MAKE SURE DIMENSIONS ARE SCALED APPROPRIATELY (I.E. -1,1 OR 0,1, STANDARDIZATION)\n",
      "mms = MinMaxScaler()\n",
      "\n",
      "# FIT\n",
      "start = time()\n",
      "grid_search_svm.fit(mms.fit_transform(data_train), targets_train)\n",
      "\n",
      "print(\"SVM Estimation using GridSearchCV took %.2f seconds\"\n",
      "      \"\\nBest Parameter settings:\" % ((time() - start)))\n",
      "print '_'*25 + '\\n'\n",
      "\n",
      "report(grid_search_svm.grid_scores_)\n",
      "best_models['svm'] = grid_search_svm.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________ Support Vector Machine Classifier ____________________\n",
        "\n",
        "SVM Estimation using GridSearchCV took 0.12 seconds\n",
        "Best Parameter settings:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "_________________________\n",
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.787 (std: 0.010)\n",
        "Parameters: {'kernel': 'linear', 'C': 0.01}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.787 (std: 0.010)\n",
        "Parameters: {'kernel': 'linear', 'C': 0.031622776601683791}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.787 (std: 0.010)\n",
        "Parameters: {'kernel': 'linear', 'C': 0.10000000000000001}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Fitting Random Forest Classifier##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '_'*20 + ' Random Forest Classifier ' + '_'*20 + '\\n'      \n",
      "# INIT RANDOM FOREST CLASSIFER\n",
      "clf_rf = RandomForestClassifier()\n",
      "\n",
      "# PARAMETER DISTRIBUTION FOR RANDOM FOREST CLASSIFIER\n",
      "param_dist_rf = {\"max_depth\": st.randint(2,5),\n",
      "                 \"n_estimators\": [20, 200],\n",
      "                 \"max_features\": st.randint(1, 11),\n",
      "                 \"min_samples_split\": st.randint(1, 11),\n",
      "                 \"min_samples_leaf\": st.randint(1, 11),\n",
      "                 \"bootstrap\": [True, False],\n",
      "                 \"criterion\": [\"gini\", \"entropy\"]}\n",
      "\n",
      "# RUN PARAMETER ESTIMATION\n",
      "n_iter_search = 20\n",
      "random_search_rf = RandomizedSearchCV(clf_rf, param_distributions=param_dist_rf,\n",
      "                                      n_iter=n_iter_search)\n",
      "# FIT\n",
      "start = time()\n",
      "random_search_rf.fit(data_train, targets_train)\n",
      "\n",
      "print(\"Random Forest Classifier Estimation using RandomizedSearchCV took %.2f seconds for %d candidates models\"\n",
      "      \"\\nBest Parameter settings:\" % ((time() - start), n_iter_search))\n",
      "print '_'*25 + '\\n'\n",
      "report(random_search_rf.grid_scores_)\n",
      "\n",
      "best_models['random_forest'] = random_search_rf.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________ Random Forest Classifier ____________________\n",
        "\n",
        "Random Forest Classifier Estimation using RandomizedSearchCV took 6.68 seconds for 20 candidates models\n",
        "Best Parameter settings:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "_________________________\n",
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.825 (std: 0.010)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'n_estimators': 20, 'min_samples_split': 7, 'criterion': 'entropy', 'max_features': 2, 'max_depth': 4}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.817 (std: 0.011)\n",
        "Parameters: {'bootstrap': True, 'min_samples_leaf': 4, 'n_estimators': 200, 'min_samples_split': 4, 'criterion': 'gini', 'max_features': 4, 'max_depth': 3}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.816 (std: 0.004)\n",
        "Parameters: {'bootstrap': False, 'min_samples_leaf': 5, 'n_estimators': 200, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 2, 'max_depth': 4}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Fitting Gradient Boosting Classifier##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print '_'*20 + ' General Gradient Boosting Classifier ' + '_'*20 + '\\n'      \n",
      "# INIT RANDOM FOREST CLASSIFER\n",
      "clf_gb = GradientBoostingClassifier(n_estimators=20)\n",
      "\n",
      "# PARAMETER DISTRIBUTION FOR RANDOM FOREST CLASSIFIER\n",
      "param_dist_gb = {\"learning_rate\": [0.001, 0.5],\n",
      "                 \"n_estimators\": st.randint(20, 201),\n",
      "                 \"max_depth\": st.randint(2,5)}\n",
      "\n",
      "# RUN PARAMETER ESTIMATION\n",
      "n_iter_search = 20\n",
      "random_search_gb = RandomizedSearchCV(clf_gb, param_distributions=param_dist_gb,\n",
      "                                      n_iter=n_iter_search)\n",
      "# FIT\n",
      "start = time()\n",
      "random_search_gb.fit(data_train, targets_train)\n",
      "\n",
      "print(\"Gradient Boosting Classifier Estimation using RandomizedSearchCV took %.2f seconds for %d candidates models\"\n",
      "      \"\\nBest Parameter settings:\" % ((time() - start), n_iter_search))\n",
      "print '_'*25 + '\\n'\n",
      "report(random_search_gb.grid_scores_)\n",
      "\n",
      "best_models['grad_boost'] = random_search_gb.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "____________________ General Gradient Boosting Classifier ____________________\n",
        "\n",
        "Gradient Boosting Classifier Estimation using RandomizedSearchCV took 11.53 seconds for 20 candidates models\n",
        "Best Parameter settings:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "_________________________\n",
        "\n",
        "Model with rank: 1\n",
        "Mean validation score: 0.823 (std: 0.010)\n",
        "Parameters: {'n_estimators': 53, 'learning_rate': 0.5, 'max_depth': 2}\n",
        "\n",
        "Model with rank: 2\n",
        "Mean validation score: 0.811 (std: 0.018)\n",
        "Parameters: {'n_estimators': 105, 'learning_rate': 0.5, 'max_depth': 3}\n",
        "\n",
        "Model with rank: 3\n",
        "Mean validation score: 0.809 (std: 0.014)\n",
        "Parameters: {'n_estimators': 102, 'learning_rate': 0.5, 'max_depth': 3}\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# WRITE OUT PREDICTIONS ON TEST SET TO CSV\n",
      "def write_prediction(outfile, pred_dict):\n",
      "    \"\"\"Write prediciton csv to <outfile>. Also takes\"\"\"\n",
      "    pred_file = open(outfile, \"wb\")\n",
      "    f = csv.writer(pred_file)\n",
      "    f.writerow(pred_dict['col_names']) # HEADER\n",
      "    f.writerows(zip(pred_dict['idx'], pred_dict['prediction']))\n",
      "    pred_file.close()\n",
      "\n",
      "data_home = \"/tmp/\"\n",
      "pred_dict = {}\n",
      "pred_dict[\"col_names\"] = [\"Passenger\", \"Survived\"]\n",
      "print \"Writing predictions to csv...\"\n",
      "for model in best_models.keys():\n",
      "    pred = best_models[model].predict(data_test)\n",
      "    pred_dict[\"idx\"] = out_idx\n",
      "    pred_dict[\"prediction\"] = pred\n",
      "    outfile = os.path.join(data_home + (model + \"_prediction.csv\"))\n",
      "    write_prediction(outfile, pred_dict)\n",
      "print \"DONE\"    \n",
      "    # SANITY CHECK\n",
      "    #print \"%s\\n\" % outfile\n",
      "    #print pred_dict\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing predictions to csv...\n",
        "DONE\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#5. Model Visualization#\n",
      "- Subpace embedding (classification)\n",
      "  - PCA \n",
      "  - LLE\n",
      "  - tsne\n",
      "- Feature Importance\n",
      "- Cluster correctly classified \n",
      "- Cluster mis-classified points\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.figure(figsize=(15,15))\n",
      "for i, model in enumerate(best_models.keys()):\n",
      "    tmp = best_models[model]\n",
      "    subplot(2,2,i)\n",
      "    xticks(arange(len(feature_labels))-.5,feature_labels,rotation=45,fontsize=10)\n",
      "    if hasattr(tmp,\"feature_importances_\"):\n",
      "        importances = tmp.feature_importances_[1:]\n",
      "        bar(arange(len(importances))-.5,importances)\n",
      "        \n",
      "        title(\"%s: feature importances\" % model,fontsize=12)\n",
      "    #elif hasattr(tmp,\"raw_coef_\"):\n",
      "    #    raw_coef = tmp.raw_coef_[0]\n",
      "    #    bar(arange(len(raw_coef)),raw_coef)\n",
      "    #    title(\"%s: Model Coefficients\" % model)\n",
      "    elif hasattr(tmp,\"coef_\"):\n",
      "        if model is \"logistic\":\n",
      "            raw_coef = tmp.coef_[0]\n",
      "        else:            \n",
      "            raw_coef = (tmp.coef_ ** 2).sum(axis=0)\n",
      "        bar(arange(len(raw_coef))-.5,raw_coef)\n",
      "        title(\"%s: model coefficients\" % model,fontsize=20)\n",
      "\n",
      "tmp = best_models['svm']\n",
      "gp = tmp.coef_\n",
      "print gp\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-0.0394351  -0.05159611 -0.03207667  0.00723111  0.02235059  0.98338663\n",
        "  -0.98338663  0.00257516  0.00213695 -0.0047121 ]]\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Gradient Boosting: Partial Dependence Plots##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
      "from sklearn.ensemble.partial_dependence import partial_dependence\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "close(\"all\")\n",
      "\n",
      "pd_features = [(0, 5), (1, 2), (5, 1)]\n",
      "fig, _ = plot_partial_dependence(best_models['grad_boost'], data_train, pd_features, feature_names=feature_labels,\n",
      "                                   n_jobs=1, grid_resolution=25)\n",
      "#fig.set_figwidth(20)\n",
      "#fig.set_figheight(8)\n",
      "plt.set_cmap(plt.cm.RdBu_r)\n",
      "plt.subplots_adjust(top=0.9)  # tight_layout causes overlap with suptitle\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#6. Interpretation & Conclusions#"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}